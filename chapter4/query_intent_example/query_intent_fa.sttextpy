#!/usr/bin/env python
#-*-coding:utf-8-*-
# @File:query_intent_fa.sttextpy
# @Author: Michael.liu
# @Date:2020/5/14 19:38
# @Desc: this code is ....

import logging
import os
import numpy as np


from random import shuffle
import fasttext.FastText as fasttext

train_file_path = u"../../data/chapter4/intent/query_intent_train_used.csv"
test_file_path = u"../../data/chapter4/intent/query_intent_test_used.csv"






def train_model(ipt=None, opt=None, model='', dim=100, epoch=5, lr=0.1, loss='softmax'):
    np.set_printoptions(suppress=True)
    if os.path.isfile(model):
        classifier = fasttext.load_model(model)
    else:
        classifier = fasttext.train_supervised(ipt, label='__label__', dim=dim, epoch=epoch,
                                         lr=lr, wordNgrams=2, loss=loss)
        """
          训练一个监督模型, 返回一个模型对象

          @param input:           训练数据文件路径
          @param lr:              学习率
          @param dim:             向量维度
          @param ws:              cbow模型时使用
          @param epoch:           次数
          @param minCount:        词频阈值, 小于该值在初始化时会过滤掉
          @param minCountLabel:   类别阈值，类别小于该值初始化时会过滤掉
          @param minn:            构造subword时最小char个数
          @param maxn:            构造subword时最大char个数
          @param neg:             负采样
          @param wordNgrams:      n-gram个数
          @param loss:            损失函数类型, softmax, ns: 负采样, hs: 分层softmax
          @param bucket:          词扩充大小, [A, B]: A语料中包含的词向量, B不在语料中的词向量
          @param thread:          线程个数, 每个线程处理输入数据的一段, 0号线程负责loss输出
          @param lrUpdateRate:    学习率更新
          @param t:               负采样阈值
          @param label:           类别前缀
          @param verbose:         ??
          @param pretrainedVectors: 预训练的词向量文件路径, 如果word出现在文件夹中初始化不再随机
          @return model object
        """
        classifier.save_model(opt)
    return classifier

dim = 100
lr = 5
epoch = 20
model = f'data_dim{str(dim)}_lr0{str(lr)}_iter{str(epoch)}.model'

classifier = train_model(ipt=train_file_path,
                         opt=model,
                         model=model,
                         dim=dim, epoch=epoch, lr=0.5
                         )

result = classifier.test(test_file_path)
# print(result)
#
#
# texts = []
# labels_right = []
# labels_predict = []
# i = 0
# top_num = 10

# with open(test_file_path,'r',encoding='utf-8') as fr:
#     lines = fr.readlines()
#
# for line in lines:
#     labels_right.append(line.split("__label__")[1].rstrip().replace("\n",""))
#     texts.append(line.split("__label__")[0].rstrip().replace("\t",""))
#
#
# labels_predict = classifier.predict(texts, top_num)
# correct_num = 0
# wrong_num = 0
#
# for i in range(0,len(labels_right)):
#    if labels_right[i] in labels_predict[i]:
#       correct_num += 1
#    else:
#       wrong_num +=1
#
# accuracy = correct_num/(correct_num+wrong_num)
#
# print("top 10 precision")
# print(accuracy)
